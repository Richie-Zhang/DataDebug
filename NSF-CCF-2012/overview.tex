\section{Data Debugging: Overview}
\label{sec:overview}


\begin{figure}[!t]
\centering
\subfigure[A spreadsheet with a typographical error.\label{fig:personal_budget}]{
  \includegraphics[width=2.5in]{overview-example}
}
\hspace{1em}
\subfigure[The same spreadsheet, with the error highlighted by \checkcell{} as the value with the most unusual impact on the computation.\label{fig:personal_budget_highlighted}]{
  \includegraphics[width=2.5in]{overview-example-highlighted}
}
\caption{A sample spreadsheet showing a personal budget. The typographical error is correctly indicated by \checkcell{}, our prototype data debugging tool for spreadsheets.}
\end{figure}

\punt{
\begin{table}[t!]
  \centering
    \begin{tabular}{|c|r|r|r|}
    \hline
    & \myalign{c|}{\textsf{\bf{A}}} & \myalign{c|}{\textsf{\bf{B}}} & \myalign{c|}{\textsf{\bf{C}}} \\
    \hline
    \textsf{\textsf{\bf{1}}} & \textsf{MONTHLY BUDGET} & \textsf{Projected Cost} & \textsf{Actual Cost} \\
    \hline
    \textsf{\textsf{\bf{2}}} & \textsf{Rent} & \textsf{\$1150}  & \textsf{\$1150} \\
    \hline
    \textsf{\textsf{\bf{3}}} & \textsf{Phone} & \textsf{\$3675}  & \textsf{\$36.75} \\
    \hline
    \textsf{\textsf{\bf{4}}} & \textsf{Gas} \& \textsf{Electricity} & \textsf{\$80}    & \textsf{\$87.23} \\
    \hline
    \textsf{\textsf{\bf{5}}} & \textsf{Waste removal} & \textsf{\$11.25} & \textsf{\$11.25} \\
    \hline
    \textsf{\textsf{\bf{6}}} & \textsf{Groceries} & \textsf{\$200}   & \textsf{\$187.81} \\
    \hline
    \textsf{\textsf{\bf{7}}} & \textsf{Car payment} & \textsf{\$225}   & \textsf{\$225} \\
    \hline
    \textsf{\textsf{\bf{8}}} & \textsf{Gasoline} & \textsf{\$50}    & \textsf{\$62.3} \\
    \hline
    \textsf{\textsf{\bf{9}}} & \textsf{Clothing} & \textsf{\$100}   & \textsf{\$59.99} \\
    \hline
    \textsf{\textsf{\bf{10}}} & \textsf{Total} & \textsf{\$5491.25} & \textsf{\$1820.33} \\
    \hline
    \textsf{\textsf{\bf{11}}} & \textsf{Fancy dinner tonight?} & \textsf{Yes}   &  \\
    \hline
    \end{tabular}%
  \caption{A sample spreadsheet showing a personal budget, with an unfortunate typographical error.\label{tab:personal_budget}}
\end{table}%
}

% in cell \texttt{B3}

% the EUSES repository~\cite{Fisher:2005:ESC:1082983.1083242}

We present an overview of data debugging, and the algorithms that it employs.
We illustrate these algorithms with a running example of a budget shown in
Figure~\ref{fig:personal_budget}, which is a reduced version of a sample
template included with Microsoft Excel. This spreadsheet tracks expected
versus real spending on monthly expenses. The spreadsheet indicates whether
the user can afford to splurge and go out to a fancy restaurant, which is when
real spending is at least \$150 less than expected. However, this example
contains an unfortunate typographical error that could lead the user to spend
money that he or she does not actually have.

% In this case, the error is relatively easy to find, but 
%finding this error manually in the original spreadsheet would be
%substantially more difficult.

\subsection{Dependence Analysis}

The first step in data debugging is to identify the relationship of
data (inputs) to computations (outputs).
In a spreadsheet, inputs are data in cells, while computations are
either charts or formulas that are not used by other formulas. \comment{Is this restriction necessary?}
%Our \checkcell{} prototype uses techniques similar to past work to identify
%dependencies in spreadsheets~\cite{fisher2006scaling}, but adds
%support for charts.
%Charts are often a key ``result'' of a spreadsheet computation, so it
%is important to detect data that triggers dramatic changes in
%charts. To handle charts, \checkcell{} treats them as if they were
%formulas that compute the average over their inputs. A data value that
%significantly alters the average is considered to have an
%unusual impact on the chart.

%\begin{figure}[!t]
%\centering
%\includegraphics[width=1.75in]{dependence-graph}
%\caption{The dependence graph that \checkcell{} extracts from the spreadsheet in Figure~\ref{fig:personal_budget}.\label{fig:dependence-graph}}
%\end{figure}

%Figure~\ref{fig:dependence-graph} shows the dependence graph that \checkcell{}
%extracts from this spreadsheet. The final formula, the only output in
%this spreadsheet (shown in black), depends on two formulas, which depend on two
%disjoint data ranges.


\subsection{Impact Analysis}

The next step is to iterate through the data itself to test the impact of each
data item on all computations. For each item, data debugging repeatedly
chooses another item from the same ``distribution'', e.g., another tuple in
the same table, or another cell in the same range, and replaces the item being
tested with the selected one. The selection process is exhaustive for small
ranges (less than 30 elements); that is, for each item, impact analysis tests
the effect of replacing it with every other item in the range. For larger
ranges, we employ random sampling.

The computations are then recalculated using this new dataset. Changes
in the computations are recorded as their \emph{impact scores} on each
data item.  The impact score for a computation depends on whether the
output is numeric or non-numeric. For numeric data, the impact score
is the absolute change from the original value.
For non-numeric data, the impact score is an \emph{indicator value}: 1
if the result of the computation changed, and 0 if not.

For the spreadsheet in Figure~\ref{fig:personal_budget}, we % \checkcell{}
start with cell \texttt{B3}. We choose an item from the same
range; for example, cell \texttt{B6}. Replacing \texttt{B3}
with \texttt{B6} results in a new sum, \$4352.50. Since this sum does
not change the \texttt{Yes} answer in the formula, the impact score
for cell \texttt{B3} remains 0.

However, the same procedure for cell \texttt{B4} is likely to have a
different effect.  For example, replacing \texttt{B4}
with \texttt{B9} yields a sum of \$1866.25. The difference
between this sum and actual spending has now dropped below \$150,
triggering a change in the result to \texttt{No}. We then
add 1 to cell \texttt{B4}'s impact score.

% Each data item maintains a separate impact score for every computation.

To minimize sampling error, random
selection for large ranges is repeated a fixed number of times (at least 30) \comment{(shouldn't this number depend on the size of the range?)},
accumulating the impact scores associated with each datum. The impact
score is then divided by the number of
iterations. 
%Section~\ref{sec:asymptotic_analysis} shows that the
%runtime efficiency of this approach is asymptotically optimal, and
%Section~\ref{sec:sampling_effectiveness} explains why sampling can be nearly as
%effective as checking each item's impact exhaustively.

\subsection{Impact Scoring}

In the final phase, the impact of each data item is normalized by transforming
it into a test statistic computed as the absolute distance of each item from
the sample mean, divided by the sample standard deviation. This
\emph{normalized impact score} represents the distance from the mean impact,
in numbers of standard deviations. A standard approach, which we adopt here,
is to only report data whose impact is at least two standard deviations away
from the mean. Note that this interpretation does not depend on normality
assumptions about the data or its impact.

Each data item's normalized impact scores are then averaged across
all the outputs, and data debugging assigns that average as the
\emph{overall impact score} of each data item. Intuitively, data with
large overall impact scores either have an extremely unusual impact on a
small number of computations, or an unusual impact on many
computations. The overall impact score is used both for ranking and
for displaying the relative anomalousness of the impact of particular
data items, e.g., by coloring such values in brighter colors
corresponding to their distance from the mean.

% ``score'' the impact by highlighting the values proportional to their z-score

% we just need to report outliers in the impact. assuming the impacts
% are normal is a conservative approach: the normal has 0 skewness
% (skew = distribution around the mean -- normal is symmetric, so 0
% skew) and low (either 0 or 3) kurtosis, depending on your definition
% of kurtosis. Every non-normal distribution is by definition more skewed and most
% distributions have a higher kurtosis (heavier tails), so we may
% overmark outliers. We won't find outliers in distributions with
% negative kurtosis, but those are super weird (no tails -- they drop
% below the x-axis at some point on either side), so it's hard to
% argue that they have outliers at all.


% \textbf{Software bugs: well-studied, effective tools.}
In many computational tasks, correctness is a primary concern. Most
work in the programming language community has
focused on ways to discover whether the program performing the
computation is correct. Techniques to reduce program errors range from
testing and runtime assertions, to dynamic and static analysis tools
that can discover a wide range of bugs. These tools and approaches enable programmers to find errors and
reduce their impact, contributing to improving overall code quality.

% ~\cite{unittesting,Miller:1990:ESR:96267.96279}
% ~\cite{samanderansthing,others}
% ~\cite{valgrind,dawsonthing,otherpcmemberfoo}

% Data errors, not so much.
However, a program is just one part of a computation. Existing tools ignore the correctness of program \emph{inputs}. If the input contains errors, the
result of the computation is likely to not be correct. Unlike
programs, data cannot easily be tested or analyzed for correctness.

Input data
errors can arise in a variety of ways~\cite{hellerstein2008quantitative}:

\begin{itemize}

\item {\bf Data entry errors}, including typographical errors and transcription errors from illegible text.

\item {\bf Measurement errors}, when the data source itself, such as a disk or a sensor, is faulty or corrupted (unintentionally or not).

\item {\bf Data integration errors}, where inconsistencies arise due to the mixing of different data, including unit of measurement mismatches.

\end{itemize}

% \textbf{Data errors really important in data-intensive programming environments.}

While data errors pose a threat to the correctness of any computation,
they are especially problematic in data-intensive programming
environments like databases, spreadsheets, and certain scientific
computations. In these
settings, data correctness can be as important as program correctness
(``garbage in, garbage out''). The results produced by the
computations---queries, formulas, charts, and other analyses---may be rendered invalid by data errors. These errors can be costly:
errors in spreadsheet data have led to losses of millions of
dollars~\cite{DBLP:journals/corr/abs-0803-2527,sakalerrors}.

%%%%  Things to add in citations: %%%%
% TransAlta took a $24 million charge -- copy and paste error
% http://www.skillsportal.co.za/page/training/articles/512049-Spreadsheet-errors-can-be-a-major-cost-to-your-business#.UJbfX2l250s
% http://www.flintshirechronicle.co.uk/flintshire-news/local-flintshire-news/2010/02/18/flintshire-county-council-school-cash-blunder-down-to-spreadsheet-error-51352-25856321/
% http://binnenland.nieuws.nl/566978


% cite approximate computation stuff?

By contrast with the proliferation of tools at a programmer's disposal
to find program errors, few tools exist to help find data errors. Part
of the problem is that it can be difficult to decide whether any given
data element is an error or not. For example, the number \texttt{1234}
might be correct, or the correct value might
be \texttt{12.34}. Typographical errors can change data items by
orders of magnitude. Unfortunately, finding this kind of mistake via
manual data auditing is onerous, unscalable, and error-prone.

% to even the moderate size of data in spreadsheets.


% \textbf{Existing approaches don't really work.}

Existing approaches to finding data errors include
\emph{data cleaning} and  \emph{statistical outlier detection}.
Data cleaning primarily copes with errors via
cross-validation with ground truth data, which may not be
present. Statistical outlier detection typically reports data as
outliers based on their relationship to a given distribution (e.g.,
Gaussian).  Automatic identification of data distributions is
error-prone and can give rise to excessive false positives.

% Non-parametric outlier detection methods
%like clustering and kernel density estimators known distributions lack
%statistical \emph{power}: they have a high probability of missing
%outliers.

%, data debugging reframes the problem to find data
%whose presence has an unusually large impact on the computation as a
%whole.

\paragraph{Contributions:}
This paper presents \emph{\bf data debugging}, an approach to locating
likely data errors. Since it is impossible to know \emph{a priori}
whether data are erroneous or not, data debugging does the next best
thing: \emph{locating data that has an unusual
impact on the computation}. Intuitively, data that has an inordinate impact on the final
result is either very important, or it is wrong. By contrast, wrong
data whose presence has no particularly unusual effect on the final result does not
merit special attention.  Data debugging combines data dependence
analysis and statistical analysis to find and rank data based on the unusualness of its
impact on the results of a computation.

Data debugging works by first building a data dependence graph of the
computations. It then measures data impact by replacing data items
with data chosen from the same group (e.g., a range in a spreadsheet
formula) and observing the resulting changes in computations that
depend on that data. This non-parametric approach allows data
debugging to find errors in both numeric and non-numeric data, without
any requirement that data follow any particular statistical
distribution.

By calling attention to data with unusual impact, data debugging can
provide insights into both the data and the computation and reveal
errors. We believe data debugging is broadly applicable, though it is
especially well-suited for data-intensive programming that intertwine
data and programs (e.g., with queries and formulas).

This paper presents the first data debugging tool in the form
of \checkcell{}, an add-in for Microsoft Excel. Spreadsheets are one
of the most widely-used programming environments, and this domain has
recently attracted renewed academic
attention~\cite{DBLP:conf/popl/Gulwani11,DBLP:conf/pldi/HarrisG11,Singh:2012:LSS:2212351.2212356}.
In addition, spreadsheet errors are a well known risk and have led to
significant monetary losses in the past, making them an excellent
first target for data debugging.

\checkcell{} highlights all data whose
impact crosses a threshold of unusualness that is more than two standard deviations away from the mean impact.  In the user interface, \checkcell{} ranks these cells by coloring them in
shades proportionally to their impact: the brighter a cell is
highlighted, the more unusual impact it has.
\checkcell{} is empirically and analytically efficient and effective, as we show in Sections~\ref{sec:analysis} and~\ref{sec:evaluation}. The current prototype is untuned but
analysis time is generally low, taking seconds to run on most of the
spreadsheets we examine. We perform a case study by employing human
workers via a crowdsourcing platform (Amazon's Mechanical Turk), and
show that \checkcell{} is effective at finding actual data entry
errors.

\section*{Outline}

The remainder of this paper is organized as
follows. Section~\ref{sec:related} discusses related
work. Section~\ref{sec:overview} describes the algorithms that data
debugging employs. Section~\ref{sec:analysis} derives analytical
results that demonstrate data debugging's runtime efficiency and
effectiveness. Section~\ref{sec:evaluation} presents an empirical
evaluation of data debugging in the form of \checkcell{}, measuring
its runtime performance and its effectiveness at finding
errors. Section~\ref{sec:future} describes directions for future work,
and Section~\ref{sec:conclusion} concludes.

%A user study verifies
%the hypothesis that data debugging's approach of identifying data with
%unusual impacts is effective at locating errors. With \checkcell{}'s
%help, users were able to find XX\% of injected errors, while users
%without \checkcell{} were only able to find YY\% of errors.


%We have developed a Microsoft Excel extension, or add-in, written in
%C\#, which uses cross-validation techniques and perturbation analysis
%to look for numerical values that appear suspicious.  Values that
%appear to be potential errors are highlighted proportionally to the
%likeliness that they are incorrect, as judged by our analysis -- the
%more likely a value is to be wrong, the brighter the highlighting.


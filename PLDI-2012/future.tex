In future work, we plan to explore applying data debugging to other
data-intensive domains, including Hadoop/MapReduce
tasks~\cite{dean2008mapreduce,hadoop}, scientific computing
environments like R~\cite{ihaka1996r}, and database management
systems, especially those with support for ``what-if''
queries~\cite{Balmin:2000:HQO:645926.672016}.

We expect all of these domains will require some tailoring of the
existing algorithms to their particular context. For databases, we
plan to treat as computations both stored procedures and cached
queries. While it is straightforward to apply data debugging to
databases when queries have no side effects, handling queries that do
modify the database will take some care in order to avoid an excessive
performance penalty due to copying.

A similar performance concern arises with Hadoop, where the key
computation is the relatively costly reduction step. Data debugging
will also likely need to take into account features of the R language
in order to work effectively in that context. Finally, we are
interested in exploring the effectiveness of data debugging in
conventional programming language settings.

%We also plan to explore other ways of ranking impacts. We
%are particularly interested in exploring the trade-off between using a
%normal distribution and non-parametric approaches like kernel
%density estimators, which can fit arbitrary distributions and
%potentially reduce the risk of false positives, at the risk of
%increasing the risk of false negatives.

While \checkcell{}'s speed is reasonable in most cases, we are
interested in further optimizing it. We are especially interested in
developing a version that incrementally updates its impacts
on-the-fly. This version would run in the background and detect 
data with unusual impacts as they are entered, much like modern text entry
underlines misspelled words. We believe that having automatic
detection of possible data errors on all the time could greatly reduce the
risk of data errors.

Testing and static analysis tools can help root out bugs in programs,
but not bugs in data. Checking data for errors is arguably as
important as finding program errors, but lacks effective tool
support. Previous approaches like data cleaning and statistical
outlier analysis require either ground truth data for
cross-validation, or that the data follow a known statistical
distribution.

This paper introduces \emph{data debugging}, an approach that
combines dataflow dependence analysis with statistical analysis to
find and rank likely data errors. Since it is impossible to
know \emph{a priori} whether data are erroneous or not, data debugging
does the next best thing: locating data where errors would have the
most impact. Data debugging works by building a dependence graph, and
then measures data impact by replacing items with randomly chosen data
from the same distribution (e.g., field entries, database columns or
spreadsheet ranges), and observing the resulting changes in
computations that depend on that data. This approach lets data
debugging find errors in both numeric and non-numeric data.

Data debugging is particularly promising in the context of
data-intensive programming environments like databases and
spreadsheets, which intertwine data with programs (in the form of
queries or formulas). This paper presents the first data debugging
tool, \checkcell{}, an add-in for Microsoft Excel. \checkcell{}
highlights unusually impactful values in shades proportional to their
effect on the spreadsheet's computation (including charts and
formulas); brighter indicates more impact. \checkcell{} is efficient;
its algorithms are asymptotically optimal, and generally runs in
seconds. We show that \checkcell{} is able to find injected errors in
a suite of real spreadsheets.

%A user study verifies the effectiveness of data debugging to
%find data errors. Users without \checkcell{} were only able to find
%errors with XX\% accuracy, while users with \checkcell{} were able to
%achieve YY\% accuracy.
